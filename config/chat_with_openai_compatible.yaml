default:
  logger:
    log_level: "INFO"
  service:
    host: "0.0.0.0"
    port: 8282
    cert_file: "ssl_certs/localhost.crt"
    cert_key: "ssl_certs/localhost.key"
  chat_engine:
    model_root: "models"
    handler_search_path:
      - "src/handlers"
    handler_configs:
      RtcClient:
        turn_config:
          turn_provider: "turn_server"
          urls: ["turn:169.63.100.185:3478", "turns:169.63.100.185:5349"]
          username: "xiuyz"
          credential: "admin"
        module: client/rtc_client/client_handler_rtc
        # max time a session will last for
        connection_ttl: 900
      SileroVad:
        module: vad/silerovad/vad_handler_silero
        speaking_threshold: 0.5
        start_delay: 2048
        end_delay: 5000
        buffer_look_back: 5000
        speech_padding: 512
      SenseVoice:
        enabled: True
        module: asr/sensevoice/asr_handler_sensevoice
        model_name: "iic/Whisper-large-v3-turbo"
        #model_name: "iic/SenseVoiceSmall"
      CosyVoice:
        enabled: True
        module: tts/cosyvoice/tts_handler_cosyvoice
        # api_url: 'http://127.0.0.1:50000/inference_sft' #run CosyVoice/runtime/python/fastapi/server.py
        model_name: "iic/CosyVoice-300M-SFT" # run cosyvoice in code
        #spk_id: "中文女" # use sft model
        ref_audio_path: "/core/dt_avatar/code/cosyvoice_ref_audio/recording_20251202_074036.wav" #use zero_shot model
        ref_audio_text: "你好，能听到我的声音吗？"
        sample_rate: 24000
        process_num: 2
      LLMOpenAICompatible:
        enabled: True
        module: llm/openai_compatible/llm_handler_openai_compatible
        model_name: "qwen-plus"
        enable_video_input: False # ensure your llm support video input
        history_length: 20
        # model_name: "gemini-2.0-flash"
        system_prompt: "Please act as an AI assistant. Answer users' questions in 2-3 concise sentences, incorporating appropriate punctuation (no need to discuss punctuation itself). Ensure your responses are in the same language as the user's question."
        api_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
        # api_url: 'http://127.0.0.1:11434/v1' # ollama
        # api_url: 'https://generativelanguage.googleapis.com/v1beta/openai/'
        api_key: 'sk-12574d385818460c84a759673209981a' # default=os.getenv("DASHSCOPE_API_KEY")
      LiteAvatar:
        module: avatar/liteavatar/avatar_handler_liteavatar
        avatar_name: 20250408/sample_data
        fps: 25
        debug: false
        enable_fast_mode: false
        use_gpu: true
